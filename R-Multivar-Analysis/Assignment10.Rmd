---
title: "Assignment10"
output: html_document
editor_options: 
  chunk_output_type: console
---

By ***Changyu Gao***, PB15121717

## 10.12
```{r}
r11 <- matrix(c(1, .8, .8, 1), nrow = 2)
r21 <- matrix(c(.26, .67, .34,
                .33, .59, .34), nrow = 3)
r12 <- t(r21)
r22 <- diag(rep.int(1, 3))
r22[lower.tri(r22)] <- r22[upper.tri(r22)] <- c(.37, .21, .35)
r1 <- rbind(cbind(r11, r12), cbind(r21, r22))
r1

# simple matrix power using spectrum decomposition
matrix_power <- function(A, p) {
  eig <- eigen(A)
  V <- eig$vectors
  L <- eig$values
  V %*% diag(L ^ p) %*% t(V)
}

p <- 2; q <- 3; n <- 70
r11sqrt <- matrix_power(r11, -1/2)
r22sqrt <- matrix_power(r22, -1/2)
A <- r11sqrt %*% r12 %*% solve(r22, r21) %*% r11sqrt
B <- r22sqrt %*% r21 %*% solve(r11, r12) %*% r22sqrt
eigA <- eigen(A)
eigB <- eigen(B)
cat("Sample canonical correlations:")
sqrt(eigA$values)
cat("First canonical pair:")
eigA$vectors[, 1] %*% r11sqrt # U_1
eigB$vectors[, 1] %*% r22sqrt # V_1

# tesing
stat <- -(n-1-(p+q+1)/2) * log(prod(1 - eigA$values))
stat
alpha <- .05
crit <- qchisq(1-alpha, p*q)
stat > crit # reject H0 if this is true

stat1 <- -(n-1-(p+q+1)/2) * log(1 - eigA$values[2])
stat1 > crit # reject H0^(1) if this is true
```
a), b) Sample canonical correlations and first canonical pairs are shown above.

In the testing, we reject $H_0$ at the $\alpha=.05$ level but do not reject $H_0^{(1)}: \rho_1^* \ne 0, \rho_2^* = 0$.

c) After some direct calculations, we obtain the table as follows
|  $X^{(1)}$  | $\hat U_1$ | $\hat V_1$ |  $X^{(2)}$  | $\hat U_1$ | $\hat V_1$ |
| :---------: | :--------: | :--------: | :---------: | :--------: | :--------: |
| $X^{(1)}_1$ |    .99     |    .68     | $X^{(2)}_1$ |    .29     |    .42     |
| $X^{(1)}_2$ |    .89     |    .61     | $X^{2)}_2$  |    .68     |    .98     |
|             |            |            | $X^{2)}_3$  |    .35     |    .51     |

d) $\hat U_1$ measures the consumption levels of households, while $\hat V_1$ is some measure of status of households based primarily on family income (also educational level and age of head).
e) We can see that status of families is positively correlated with their consumption levels. That is to say, households with higher income tend to consume more. Conversely, families with higher consumption levels are often wealthier.

## 10.13
```{r}
r2 <- as.matrix(read.table("10-13.txt"))
r11 <- r2[1:5, 1:5]
r21 <- r2[6:9, 1:5]
r12 <- t(r21)
r22 <- r2[6:9, 6:9]

p <- 5; q <- 4; n <- 138
r11sqrt <- matrix_power(r11, -1/2)
r22sqrt <- matrix_power(r22, -1/2)
A <- r11sqrt %*% r12 %*% solve(r22, r21) %*% r11sqrt
B <- r22sqrt %*% r21 %*% solve(r11, r12) %*% r22sqrt
eigA <- eigen(A)
eigB <- eigen(B)
cat("Sample canonical correlations:")
sqrt(eigA$values[1:4])

# tesing
stat <- -(n-1-(p+q+1)/2) * log(prod(1 - eigA$values))
stat
alpha <- .01
crit <- qchisq(1-alpha, p*q)
stat > crit # reject H0 if this is true

stat1 <- -(n-1-(p+q+1)/2) * log(prod(1 - eigA$values[-1]))
stat1 > crit # reject H0^(1) if this is true
stat2 <- -(n-1-(p+q+1)/2) * log(prod(1 - eigA$values[c(-1, -2)]))
stat2 > crit # reject H0^(2) if this is true

eigA$vectors[, 1] %*% r11sqrt # U_1
eigB$vectors[, 1] %*% r22sqrt # V_1

eigA$vectors[, 2] %*% r11sqrt # U_2
eigB$vectors[, 2] %*% r22sqrt # V_2

Az_inv <- solve(t(eigA$vectors[]) %*% r11sqrt)
v1 <- Az_inv[,1]
sum(diag(v1 %o% v1)) / p # proportion explained

Bz_inv <- solve(t(eigB$vectors[]) %*% r22sqrt)
v2 <- Bz_inv[,1]
sum(diag(v2 %o% v2)) / q # proportion explained
```
a) At the $\alpha = .01$ level, we reject $H_0,H_0^(1)$ but do not reject $H_0^(2): \rho_1^* \ne 0, \rho_2^* \ne 0, \rho_3^* = 0,\rho_4^* = 0$

Significant sample canonical variates are shown above.

b) Yes. $\hat U_1$ contrasts "damaged kernels", "foreign material" with other quality figures. $\hat V_1$ combines those quality figures.

c) We compute that the proportion explained is 62.9% and 45.0% respectively.

## 11.23
```{r}
X <- read.table("T1-6.DAT")
head(X)
splitX <- split(X[,-6], X$V6)
nonmult <- splitX[[1]]
mult <- splitX[[2]]
n1 <- nrow(nonmult)
n2 <- nrow(mult)
plotqq <- function(col, title="") {
  qqp <- qqnorm(col, main = title)
  qqline(col)
  with(qqp, cor(x, y))
}
layout(matrix(1:10, nrow = 2, byrow = TRUE), respect = TRUE)
par(mar=rep.int(1,4))
nonmult.rqs <-  sapply(nonmult, plotqq)
mult.rqs <-  sapply(mult, plotqq)
nonmult.rqs
mult.rqs
nonmult_trans <- nonmult
mult_trans <- mult
nonmult_trans[,1] <- log(nonmult[,1])
nonmult_trans[,3] <- log(nonmult[,3] + 1)
nonmult_trans[,5] <- log(nonmult[,5] + 1)
mult_trans[,1] <- log(mult[,1])
mult_trans[,3] <- log(mult[,3] + 1)
mult_trans[,5] <- log(mult[,5] + 1)
layout(matrix(1:10, nrow = 2, byrow = TRUE), respect = TRUE)
par(mar=rep.int(1,4))
nonmult.rqs <-  sapply(nonmult_trans, plotqq)
mult.rqs <-  sapply(mult_trans, plotqq)
nonmult.rqs
mult.rqs
```
a) As we can see for non-multiple-sclerosis group, only V4 has a qr > 0.97 Thus we remain skeptical about the normality assumption.
For multiple-sclerosis group, V1, V2 and V4 all have qrs > 0.97 while qrs of V3 and V5 are less than 0.85.

After logarithm transformation, $ln(x_1), ln(x_3+1), ln(x_5+1)$ appears to be normal. (Add 1 for $x_3, x_5$ since some values are close to 0.)

```{r}
nonmult_avg <- colMeans(nonmult)
mult_avg <- colMeans(mult)
S1 <- cov(nonmult)
S2 <- cov(mult)
Spool <- ((n1-1) * S1 + (n2-1) * S2) / (n1+n2-2)
d <- nonmult_avg - mult_avg
coefs <- solve(Spool, d) # coefs of discriminant function
coefs

m <- sum(solve(Spool, d) * (nonmult_avg + mult_avg) / 2)
m # mhat
```
As shown above, we allocate x0 to $\pi_1$ if
$.023x_1 - .034x_2 + .21x_3 - .08x_4 - .25x_5 + 23.23 \ge 0$
Otherwise, allocate it to $\pi_2$
From this function, we know that first two variables appeart to be less important.

```{r}
predicted1 <- as.matrix(nonmult) %*% coefs
conf <- matrix(nrow = 2, ncol = 2)
conf[1,1] <- sum(predicted1 >= m)
conf[1,2] <- n1 - conf[1,1]

# mult
predicted2 <- as.matrix(mult) %*% coefs
conf[2,1] <- sum(predicted2 >= m)
conf[2,2] <- n2 - conf[2,1]

# confusion matrix
conf

APER <- (conf[1,2] + conf[2,1]) / (n1 + n2)
APER
```
The confusion matrix is shown above. APER is about $0.102$
